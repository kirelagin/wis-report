Предварительная обработка
--------------------------

Статья википедии представляет собой текст, отформатированный с помощью вики-разметки. Это позволяет новичкам быстро освоить основы оформления.
К сожалению, у вики-разметки есть серьезный недостаток: она никак не стандартизована. По этой причине абсолютно корректный парсер реализовать невозможно.
Обилие недокументированных возможностей, крайних случаев и ошибок, активно используемых авторами статей, сводит к нулю возможность стандартизации.

Для построения поискового индекса первым делом необходимо отделить слова от разметки. Оказалось, что, в силу изложенного выше, задача эта крайне трудна.
Наш индексатор использует нетривиальный алгоритм удаления вики-разметки и html-тегов, основанный на исходном коде проекта Tanl[@tanl],
и состоящий, по сути, из большого числа регулярных выражений.
После этого все небезопасные с точки зрения HTML символы (`<`, `>`, `&`) экранируются.


Построение индекса и коллекции документов
------------------------------------------

Полученный в результате удаления разметки текст разделяется на токены.
Для облегчения задачи первым делом с помощью токенизтора `PunktSentenceTokenizer` из библиотеки _NLTK_[@nltk] (оригинальное описание которого можно найти в статье [@punkt])
выделяются отдельные предложения. Затем, каждое предложении по отдельности обрабатывается модифицированной версией токенизатора `Penn Treebank`[@treebank].

На следующем этапе полученный поток токенов фильтруется, чтобы исключить из него пунктуацию и стоп-слова, а после — нормализуется.
Нормализация включает в себя приведение слова к основе (стемматизацию) с помощью алгоритма, известного как `Porter2`[@porter2]. Полученные стемы сохраняются
в индекс вместе с идентификаторами документов, в которых они встретились, и точными позициями в этих документах (постингами). В качестве идентификаторов
документов мы используем sha1-хэши ревизий, содержащиеся в файле с экспортированными статьями.

Кроме того, информация о документе (заголовок, текст, размер), а также разбиение на токены записываются в базу данных документов (коллекцию), позволяющую
извлекать все эти сведения по идентификатору документа, то есть по хэшу. Помимо этого, в базе данных хранится мета-информация о коллекции (число документов,
средняя длина документа), необходимая для ранжирования поисковой выдачи (см. далее).


Простой поиск
--------------

Задача системы — по запросу пользователя найти наиболее подходящие (релевантные) документы. Поисковый запрос — это просто строка текста, потому
важно правильно выделить из неё ключевые слова. Запрос токенизируется и нормализуется подобно тому, как это происходит с текстом при индексации;
выделяется полезная для успешного поиска информация. Оставшиеся после фильтрации и нормализации основы используются для извлечения постингов из индекса.

Мы решили, что в условиях конкретной задачи (поиск по электронной энциклопедии) вполне уместно требовать, чтобы все слова из поискового запроса
(точнее, все не отфильтрованные в результате предобработки запроса) содержались в выдаваемых документах, то есть итоговое множество документов —
пересечение результатов запросов к индексу для каждого слова в отдельности.

Следует отметить, что в случае более общего поиска по интернету такой подход, возможно, будет приводить к несколько более плохим результатам.


Ранжирование
-------------

Ранжирование документов в нашей поисковой системе основано на модифицированном алгоритме _BM25_[@okapi] (также известном как _Okapi BM25_).


### BM25

После того, как получено множество документов, удовлетворяющих запросу, для каждого документа ($D$) вычисляется релевантность запросу ($Q$) по формуле

$$\text{score}(D,Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \cdot \frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{\text{avgdl}})},$$

где $f(q_i, D)$ — частота термина $q_i$ в документе $D$, $|D|$ — размер документа $D$, $\text{avgdl}$ — средний размер документа в коллекции.
Константы $k_1 = 1.6$ и $b = 0.75$ выбраны в соответствии с рекомендациями, приведенными в [@manning].

$\text{IDF}(q_i) = \log \frac{N - n(q_i) + 0.5}{n(q_i) + 0.5},$ где $N$ — число документов в коллекции, а $n(q_i)$ — число документов, содержащих термин $q_i$.

$f(q_i, D)$ вычисляется как отношение числа вхождений термина в документ к размеру документа; число вхождений термина известно после запроса к индексу,
а размер каждого документа, равно как число документов и их средний размер, хранятся в базе данных документов. $n(q_i)$ может быть определено с помощью
информации, содержащейся в ответе, полученном от индекса.

Такая схема ранжирования работает неплохо, но не достаточно хорошо.


### Дополнительные эвристики

У Википедии есть важная особенность: часто наилучшим ответом на запрос будет статья, название которой в точности совпадает с самим запросом.
Таким образом, при ранжировании необходимо придавать дополнительный вес заголовку статьи.

К примеру, очевидно, что по запросу «engineering» на первом месте следует вывести статью «Engineering». Если использовать только алгоритм _BM25_, то
упомянутая статья оказывается на третьей странице поисковой выдачи (в районе третьего десятка), что, конечно же, нельзя считать удовлетворительным результатом.

#### Эвристика №1 (по основам слов в заголовке)

Первая эвристика поощряет статьи, содержащие в заголовке слова из поискового запроса; чем точнее заголовок соответствует запросу, тем заметнее
статья поднимается наверх в выдаче. Максимальный бонус от этой эвристики получит статья, содержащая в заголовке все термины из запроса
(точнее, все неотфильтрованные в результате предобработки запроса термины).

Такая специализация ранжирования дает ощутимый положительный результат, но рассмотренный пример статьи «Engineering» показывает, что этого недостаточно,
поскольку статья поднимается лишь на вторую страницу. Дело в том, что многие другие статьи («Traffic engineering», «Social engineering», «Network engineering», …)
также получают максимальный бонус.

#### Эвристика №2 (по точным соответствиям в заголовке)

У предыдущей эвристики есть еще один недостаток. Она учитывает только основы слов, а не точные формы. Это позволяет успешно выбирать статьи,
подходящие под тематику запроса, но не сильно влияет на порядок статей внутри одной темы. К примеру, слова «engineering» и «engineer» имеют одинаковую
основу, следовательно оба получат максимальный балл. В то время как очевидно, что, если пользователь ввел запрос «engineer», то статья «Engineer» более релевантна,
нежели статья «Engineering».

Вторая эвристика работает с неотфильтрованными (только лишь токенизированными) запросом и заголовком. Она учитывает не только формы слов, но и точное число
вхождений каждой формы. Кроме того, поскольку производится лишь минимальная нормализация, а фильтрация не производится вообще, учитываются также
слова из стоп-листа и пунктуация.

Именно благодаря этой эвристике наша поисковая система по запросу «engineer» на первом месте выводит статью «Engineer», а по запросу «engineering» —
статью «Engineering». Эта же эвристика поднимает на первое место статью «Apple I» по запросу «apple I» (хотя «I» — стоп-слово).

Принципиальное отличие от эвристики, описанной в предыдущем разделе, заключается в том, что теперь мы поощряем статьи не за факт наличия
«правильного» слова в заголовке, а также за отсутствие «неправильных» слов. Здесь максимальный бонус получит статья, содержащая в заголовке в точности
все слова (и символы) из запроса в тех же самых формах, _и_ не содержащая ничего другого. Таким образом, по запросу «engineering» статья
«Engineering» окажется в выдаче выше, чем «Network engineering», поскольку вторая содержит лишнее слово. Кроме того, как уже было замечено,
учитывается не только наличие или отсутствие токенов, но и их число. Потому, по запросу «please please» статья о песне «Please Please Me» окажется
выше, чем статья о слове «Please».


Исправление опечаток
---------------------

Простейшее исправление опечаток работает следующим образом. Если при точном поиске основы в индексе не было обнаружено ни одного документа, значит, в запросе, скорее всего,
присутствует опечатка. В этом случае делается нечеткий запрос к индексу, возвращающий постинги всех основ, находящихся на небольшом редакционном расстоянии от искомой.

Оказалось, что такой подход имеет целый ряд недостатков. Во-первых, с ним не будет работать описанная выше под номером 2 эвристика. На первый взгляд, потеря не
велика, но на самом деле качество поиска ухудшается заметно. Во-вторых, такой подход довольно плохо сочетается с выделением основ слов (стеммингом). К примеру,
используемый нами алгоритм стемминга для слова «computer» выдаст основу «comput», а слово «cmputer» не изменит. Как видно, исходные слова различаются
одной буквой, а полученные основы — тремя. Этих двух неприятных фактов достаточно, чтобы сделать вывод о необходимости исправления опечаток _перед_ нормализацией запроса.

#### Исправление опечаток до нормализации запроса

Для обнаружения и исправления опечаток требуется словарь. В нашем случае гибкость системы управления индексом позволила легко использовать тот же самый индекс, как словарь.
Для этого исходные формы слов добавлялись в основной индекс с пустым списком постингов. Это никак не повлияет на объем значений, хранимых в индексе, а лишь увеличит число ключей,
что не столь критично.

Теперь каждое слово запроса можно проверить по составленному словарю. Если слова в словаре нет, то, скорее всего, пользователь допустил в нем опечатку
(либо не допустил, но искать это слово нет смысла, поскольку если его нет в словаре, то и в текстах статей оно не встречается). Затем, можно
выполнить нечеткий поиск по словарю, который вернет все словарные слова, похожие на введенное пользователем. Если среди найденных вариантов окажется верное
исправление опечатки, то последующий стемминг нового слова вернет правильную основу и, что тоже важно, сработают обе эвристики.

Наша система, в отличие от некоторых других, нацелена не на то, чтобы угадать единственный верный вариант исправления. Она постaрается найти статьи,
подходящие под все возможные (и уместные) варианты исправления ошибки. К пример, по запросу «tember» первые шесть статей будут (именно в таком порядке):

* **Timber** (disambiguation)
* International Tropical **Timber** Agreement, 1994
* International Tropical **Timber** Agreement, 1983
* **Temperate** climate
* List of The Yardbirds **members**
* **Member** states of the United Nations
